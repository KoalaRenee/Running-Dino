{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca977445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for jetson: \n",
      "crw-rw----+ 1 root video 81, 0 May 31 19:58 /dev/video0\n"
     ]
    }
   ],
   "source": [
    "# Full reset of the camera\n",
    "!echo 'jetson' | sudo -S systemctl restart nvargus-daemon && printf '\\n'\n",
    "# Check device number\n",
    "!ls -ltrh /dev/video*\n",
    "\n",
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "camera = CSICamera(width=640, height=480, capture_fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3673c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdce09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESH = 0.5\n",
    "IOU_THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c560179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_path_batches(batch_size, img_dir):\n",
    "    ret = []\n",
    "    batch = []\n",
    "    for root, dirs, files in os.walk(img_dir):\n",
    "        for name in files:\n",
    "            if len(batch) == batch_size:\n",
    "                ret.append(batch)\n",
    "                batch = []\n",
    "            batch.append(os.path.join(root, name))\n",
    "    if len(batch) > 0:\n",
    "        ret.append(batch)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_box(x, img, color=None, label=None, line_thickness=None):\n",
    "    \"\"\"\n",
    "    description: Plots one bounding box on image img,\n",
    "                 this function comes from YoLov5 project.\n",
    "    param: \n",
    "        x:      a box likes [x1,y1,x2,y2]\n",
    "        img:    a opencv image object\n",
    "        color:  color to draw rectangle, such as (0,255,0)\n",
    "        label:  str\n",
    "        line_thickness: int\n",
    "    return:\n",
    "        no return\n",
    "\n",
    "    \"\"\"\n",
    "    tl = (\n",
    "        line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1\n",
    "    )  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            label,\n",
    "            (c1[0], c1[1] - 2),\n",
    "            0,\n",
    "            tl / 3,\n",
    "            [225, 255, 255],\n",
    "            thickness=tf,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4701caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoLov5TRT(object):\n",
    "    \"\"\"\n",
    "    description: A YOLOv5 class that warps TensorRT ops, preprocess and postprocess ops.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, engine_file_path):\n",
    "        # Create a Context on this device,\n",
    "        self.ctx = cuda.Device(0).make_context()\n",
    "        stream = cuda.Stream()\n",
    "        TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "        runtime = trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "        # Deserialize the engine from file\n",
    "        with open(engine_file_path, \"rb\") as f:\n",
    "            engine = runtime.deserialize_cuda_engine(f.read())\n",
    "        context = engine.create_execution_context()\n",
    "\n",
    "        host_inputs = []\n",
    "        cuda_inputs = []\n",
    "        host_outputs = []\n",
    "        cuda_outputs = []\n",
    "        bindings = []\n",
    "\n",
    "        for binding in engine:\n",
    "            print('bingding:', binding, engine.get_binding_shape(binding))\n",
    "            size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "            # Allocate host and device buffers\n",
    "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "            cuda_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            # Append the device buffer to device bindings.\n",
    "            bindings.append(int(cuda_mem))\n",
    "            # Append to the appropriate list.\n",
    "            if engine.binding_is_input(binding):\n",
    "                self.input_w = engine.get_binding_shape(binding)[-1]\n",
    "                self.input_h = engine.get_binding_shape(binding)[-2]\n",
    "                host_inputs.append(host_mem)\n",
    "                cuda_inputs.append(cuda_mem)\n",
    "            else:\n",
    "                host_outputs.append(host_mem)\n",
    "                cuda_outputs.append(cuda_mem)\n",
    "\n",
    "        # Store\n",
    "        self.stream = stream\n",
    "        self.context = context\n",
    "        self.engine = engine\n",
    "        self.host_inputs = host_inputs\n",
    "        self.cuda_inputs = cuda_inputs\n",
    "        self.host_outputs = host_outputs\n",
    "        self.cuda_outputs = cuda_outputs\n",
    "        self.bindings = bindings\n",
    "        self.batch_size = engine.max_batch_size\n",
    "\n",
    "    def infer(self, raw_image_generator):\n",
    "        threading.Thread.__init__(self)\n",
    "        # Make self the active context, pushing it on top of the context stack.\n",
    "        self.ctx.push()\n",
    "        # Restore\n",
    "        stream = self.stream\n",
    "        context = self.context\n",
    "        engine = self.engine\n",
    "        host_inputs = self.host_inputs\n",
    "        cuda_inputs = self.cuda_inputs\n",
    "        host_outputs = self.host_outputs\n",
    "        cuda_outputs = self.cuda_outputs\n",
    "        bindings = self.bindings\n",
    "        # Do image preprocess\n",
    "        batch_image_raw = []\n",
    "        batch_origin_h = []\n",
    "        batch_origin_w = []\n",
    "        batch_input_image = np.empty(shape=[self.batch_size, 3, self.input_h, self.input_w])\n",
    "        for i, image_raw in enumerate(raw_image_generator):\n",
    "            input_image, image_raw, origin_h, origin_w = self.preprocess_image(image_raw)\n",
    "            batch_image_raw.append(image_raw)\n",
    "            batch_origin_h.append(origin_h)\n",
    "            batch_origin_w.append(origin_w)\n",
    "            np.copyto(batch_input_image[i], input_image)\n",
    "        batch_input_image = np.ascontiguousarray(batch_input_image)\n",
    "        start = time.time()\n",
    "        # Copy input image to host buffer\n",
    "        np.copyto(host_inputs[0], batch_input_image.ravel())\n",
    "        # Transfer input data  to the GPU.\n",
    "        cuda.memcpy_htod_async(cuda_inputs[0], host_inputs[0], stream)\n",
    "        # Run inference.\n",
    "        context.execute_async(batch_size=self.batch_size, bindings=bindings, stream_handle=stream.handle)\n",
    "        # Transfer predictions back from the GPU.\n",
    "        cuda.memcpy_dtoh_async(host_outputs[0], cuda_outputs[0], stream)\n",
    "        # Synchronize the stream\n",
    "        stream.synchronize()\n",
    "        end = time.time()\n",
    "        # Remove any context from the top of the context stack, deactivating it.\n",
    "        self.ctx.pop()\n",
    "        # Here we use the first row of output in that batch_size = 1\n",
    "        output = host_outputs[0]\n",
    "        # Do postprocess\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        ids = []\n",
    "        for i in range(self.batch_size):\n",
    "            result_boxes, result_scores, result_classid = self.post_process(\n",
    "                output[i * 6001: (i + 1) * 6001], batch_origin_h[i], batch_origin_w[i]\n",
    "            )\n",
    "            boxes.append(result_boxes)\n",
    "            scores.append(result_scores)\n",
    "            ids.append(result_classid)\n",
    "            # Draw rectangles and labels on the original image\n",
    "            for j in range(len(result_boxes)):\n",
    "                box = result_boxes[j]\n",
    "#                 plot_one_box(\n",
    "#                     box,\n",
    "#                     batch_image_raw[i],\n",
    "#                     label=\"{}:{:.2f}\".format(\n",
    "#                         categories[int(result_classid[j])], result_scores[j]\n",
    "#                     ),\n",
    "#                 )\n",
    "        return batch_image_raw, end - start, boxes, scores, ids\n",
    "\n",
    "    def destroy(self):\n",
    "        # Remove any context from the top of the context stack, deactivating it.\n",
    "        self.ctx.pop()\n",
    "        \n",
    "    def get_raw_image(self, image_path_batch):\n",
    "        \"\"\"\n",
    "        description: Read an image from image path\n",
    "        \"\"\"\n",
    "        for img_path in image_path_batch:\n",
    "            yield cv2.imread(img_path)\n",
    "        \n",
    "    def get_raw_image_zeros(self, image_path_batch=None):\n",
    "        \"\"\"\n",
    "        description: Ready data for warmup\n",
    "        \"\"\"\n",
    "        for _ in range(self.batch_size):\n",
    "            yield np.zeros([self.input_h, self.input_w, 3], dtype=np.uint8)\n",
    "\n",
    "    def preprocess_image(self, raw_bgr_image):\n",
    "        \"\"\"\n",
    "        description: Convert BGR image to RGB,\n",
    "                     resize and pad it to target size, normalize to [0,1],\n",
    "                     transform to NCHW format.\n",
    "        param:\n",
    "            input_image_path: str, image path\n",
    "        return:\n",
    "            image:  the processed image\n",
    "            image_raw: the original image\n",
    "            h: original height\n",
    "            w: original width\n",
    "        \"\"\"\n",
    "        image_raw = raw_bgr_image\n",
    "        h, w, c = image_raw.shape\n",
    "        image = cv2.cvtColor(image_raw, cv2.COLOR_BGR2RGB)\n",
    "        # Calculate widht and height and paddings\n",
    "        r_w = self.input_w / w\n",
    "        r_h = self.input_h / h\n",
    "        if r_h > r_w:\n",
    "            tw = self.input_w\n",
    "            th = int(r_w * h)\n",
    "            tx1 = tx2 = 0\n",
    "            ty1 = int((self.input_h - th) / 2)\n",
    "            ty2 = self.input_h - th - ty1\n",
    "        else:\n",
    "            tw = int(r_h * w)\n",
    "            th = self.input_h\n",
    "            tx1 = int((self.input_w - tw) / 2)\n",
    "            tx2 = self.input_w - tw - tx1\n",
    "            ty1 = ty2 = 0\n",
    "        # Resize the image with long side while maintaining ratio\n",
    "        image = cv2.resize(image, (tw, th))\n",
    "        # Pad the short side with (128,128,128)\n",
    "        image = cv2.copyMakeBorder(\n",
    "            image, ty1, ty2, tx1, tx2, cv2.BORDER_CONSTANT, None, (128, 128, 128)\n",
    "        )\n",
    "        image = image.astype(np.float32)\n",
    "        # Normalize to [0,1]\n",
    "        image /= 255.0\n",
    "        # HWC to CHW format:\n",
    "        image = np.transpose(image, [2, 0, 1])\n",
    "        # CHW to NCHW format\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        # Convert the image to row-major order, also known as \"C order\":\n",
    "        image = np.ascontiguousarray(image)\n",
    "        return image, image_raw, h, w\n",
    "\n",
    "    def xywh2xyxy(self, origin_h, origin_w, x):\n",
    "        \"\"\"\n",
    "        description:    Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "        param:\n",
    "            origin_h:   height of original image\n",
    "            origin_w:   width of original image\n",
    "            x:          A boxes numpy, each row is a box [center_x, center_y, w, h]\n",
    "        return:\n",
    "            y:          A boxes numpy, each row is a box [x1, y1, x2, y2]\n",
    "        \"\"\"\n",
    "        y = np.zeros_like(x)\n",
    "        r_w = self.input_w / origin_w\n",
    "        r_h = self.input_h / origin_h\n",
    "        if r_h > r_w:\n",
    "            y[:, 0] = x[:, 0] - x[:, 2] / 2\n",
    "            y[:, 2] = x[:, 0] + x[:, 2] / 2\n",
    "            y[:, 1] = x[:, 1] - x[:, 3] / 2 - (self.input_h - r_w * origin_h) / 2\n",
    "            y[:, 3] = x[:, 1] + x[:, 3] / 2 - (self.input_h - r_w * origin_h) / 2\n",
    "            y /= r_w\n",
    "        else:\n",
    "            y[:, 0] = x[:, 0] - x[:, 2] / 2 - (self.input_w - r_h * origin_w) / 2\n",
    "            y[:, 2] = x[:, 0] + x[:, 2] / 2 - (self.input_w - r_h * origin_w) / 2\n",
    "            y[:, 1] = x[:, 1] - x[:, 3] / 2\n",
    "            y[:, 3] = x[:, 1] + x[:, 3] / 2\n",
    "            y /= r_h\n",
    "\n",
    "        return y\n",
    "\n",
    "    def post_process(self, output, origin_h, origin_w):\n",
    "        \"\"\"\n",
    "        description: postprocess the prediction\n",
    "        param:\n",
    "            output:     A numpy likes [num_boxes,cx,cy,w,h,conf,cls_id, cx,cy,w,h,conf,cls_id, ...] \n",
    "            origin_h:   height of original image\n",
    "            origin_w:   width of original image\n",
    "        return:\n",
    "            result_boxes: finally boxes, a boxes numpy, each row is a box [x1, y1, x2, y2]\n",
    "            result_scores: finally scores, a numpy, each element is the score correspoing to box\n",
    "            result_classid: finally classid, a numpy, each element is the classid correspoing to box\n",
    "        \"\"\"\n",
    "        # Get the num of boxes detected\n",
    "        num = int(output[0])\n",
    "        # Reshape to a two dimentional ndarray\n",
    "        pred = np.reshape(output[1:], (-1, 6))[:num, :]\n",
    "        # Do nms\n",
    "        boxes = self.non_max_suppression(pred, origin_h, origin_w, conf_thres=CONF_THRESH, nms_thres=IOU_THRESHOLD)\n",
    "        result_boxes = boxes[:, :4] if len(boxes) else np.array([])\n",
    "        result_scores = boxes[:, 4] if len(boxes) else np.array([])\n",
    "        result_classid = boxes[:, 5] if len(boxes) else np.array([])\n",
    "        return result_boxes, result_scores, result_classid\n",
    "\n",
    "    def bbox_iou(self, box1, box2, x1y1x2y2=True):\n",
    "        \"\"\"\n",
    "        description: compute the IoU of two bounding boxes\n",
    "        param:\n",
    "            box1: A box coordinate (can be (x1, y1, x2, y2) or (x, y, w, h))\n",
    "            box2: A box coordinate (can be (x1, y1, x2, y2) or (x, y, w, h))            \n",
    "            x1y1x2y2: select the coordinate format\n",
    "        return:\n",
    "            iou: computed iou\n",
    "        \"\"\"\n",
    "        if not x1y1x2y2:\n",
    "            # Transform from center and width to exact coordinates\n",
    "            b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "            b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "            b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "            b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "        else:\n",
    "            # Get the coordinates of bounding boxes\n",
    "            b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "            b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "\n",
    "        # Get the coordinates of the intersection rectangle\n",
    "        inter_rect_x1 = np.maximum(b1_x1, b2_x1)\n",
    "        inter_rect_y1 = np.maximum(b1_y1, b2_y1)\n",
    "        inter_rect_x2 = np.minimum(b1_x2, b2_x2)\n",
    "        inter_rect_y2 = np.minimum(b1_y2, b2_y2)\n",
    "        # Intersection area\n",
    "        inter_area = np.clip(inter_rect_x2 - inter_rect_x1 + 1, 0, None) * \\\n",
    "                     np.clip(inter_rect_y2 - inter_rect_y1 + 1, 0, None)\n",
    "        # Union Area\n",
    "        b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "        b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "        iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def non_max_suppression(self, prediction, origin_h, origin_w, conf_thres=0.5, nms_thres=0.4):\n",
    "        \"\"\"\n",
    "        description: Removes detections with lower object confidence score than 'conf_thres' and performs\n",
    "        Non-Maximum Suppression to further filter detections.\n",
    "        param:\n",
    "            prediction: detections, (x1, y1, x2, y2, conf, cls_id)\n",
    "            origin_h: original image height\n",
    "            origin_w: original image width\n",
    "            conf_thres: a confidence threshold to filter detections\n",
    "            nms_thres: a iou threshold to filter detections\n",
    "        return:\n",
    "            boxes: output after nms with the shape (x1, y1, x2, y2, conf, cls_id)\n",
    "        \"\"\"\n",
    "        # Get the boxes that score > CONF_THRESH\n",
    "        boxes = prediction[prediction[:, 4] >= conf_thres]\n",
    "        # Trandform bbox from [center_x, center_y, w, h] to [x1, y1, x2, y2]\n",
    "        boxes[:, :4] = self.xywh2xyxy(origin_h, origin_w, boxes[:, :4])\n",
    "        # clip the coordinates\n",
    "        boxes[:, 0] = np.clip(boxes[:, 0], 0, origin_w -1)\n",
    "        boxes[:, 2] = np.clip(boxes[:, 2], 0, origin_w -1)\n",
    "        boxes[:, 1] = np.clip(boxes[:, 1], 0, origin_h -1)\n",
    "        boxes[:, 3] = np.clip(boxes[:, 3], 0, origin_h -1)\n",
    "        # Object confidence\n",
    "        confs = boxes[:, 4]\n",
    "        # Sort by the confs\n",
    "        boxes = boxes[np.argsort(-confs)]\n",
    "        # Perform non-maximum suppression\n",
    "        keep_boxes = []\n",
    "        while boxes.shape[0]:\n",
    "            large_overlap = self.bbox_iou(np.expand_dims(boxes[0, :4], 0), boxes[:, :4]) > nms_thres\n",
    "            label_match = boxes[0, -1] == boxes[:, -1]\n",
    "            # Indices of boxes with lower confidence scores, large IOUs and matching labels\n",
    "            invalid = large_overlap & label_match\n",
    "            keep_boxes += [boxes[0]]\n",
    "            boxes = boxes[~invalid]\n",
    "        boxes = np.stack(keep_boxes, 0) if len(keep_boxes) else np.array([])\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf326a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bingding: data (3, 640, 640)\n",
      "bingding: prob (6001, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# load custom plugin and engine\n",
    "PLUGIN_LIBRARY = \"build/libmyplugins.so\"\n",
    "engine_file_path = \"build/yolov5s.engine\"\n",
    "\n",
    "ctypes.CDLL(PLUGIN_LIBRARY)\n",
    "\n",
    "# load coco labels\n",
    "# categories = [\"bin\", \"station\"]\n",
    "categories = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\",\n",
    "            \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
    "            \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
    "            \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "            \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "            \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
    "            \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "            \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
    "            \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "yolov5_wrapper = YoLov5TRT(engine_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e2ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef01090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f14fe1570594968ae769c55963e1935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ae02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24434828758239746\n",
      "0.2710456848144531\n",
      "0.2582094669342041\n",
      "0.24546456336975098\n",
      "0.23699522018432617\n",
      "0.23811984062194824\n",
      "0.25554847717285156\n",
      "0.25487685203552246\n",
      "0.2313706874847412\n",
      "0.2444286346435547\n",
      "0.2593662738800049\n",
      "0.2535402774810791\n",
      "0.22131800651550293\n",
      "0.2614099979400635\n",
      "0.2427983283996582\n",
      "0.2715928554534912\n",
      "0.243011474609375\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    image = camera.value\n",
    "#     st = time.time()\n",
    "    batch_image_raw, use_time, boxes, scores, ids = yolov5_wrapper.infer([image])\n",
    "#     print(time.time()-st)\n",
    "    print(use_time)\n",
    "    boxes = boxes[0]\n",
    "    scores = scores[0]\n",
    "    ids = ids[0]\n",
    "    image = batch_image_raw[0]\n",
    "    for i in range(len(ids)):\n",
    "        if ids[i] == 0:\n",
    "            box = boxes[i]\n",
    "            if box[3] < 440:\n",
    "#                 print('jump')\n",
    "                image = cv2.putText(image, 'jump', (0,50), 0, 3, (255,0,0), 2, cv2.LINE_AA)\n",
    "            elif box[3]-box[1] < 360:\n",
    "#                 print('knee')\n",
    "                image = cv2.putText(image, 'knee', (0,50), 0, 3, (255,0,0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "#                 print('none')\n",
    "                image = cv2.putText(image, 'none', (0,50), 0, 3, (255,0,0), 2, cv2.LINE_AA)\n",
    "            break\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "#     print(boxes, scores, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be44971",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5_wrapper.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973cab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54e319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
